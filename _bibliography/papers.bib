---
---

@inproceedings{zhang-etal-2023-causal,
  title = "Causal Reasoning of Entities and Events in Procedural Texts",
  author = "Zhang, Li  and
  Xu, Hainiu  and Yang, Yue  and
  Zhou, Shuyan  and
  You, Weiqiu  and
  Arora, Manni  and
  Callison-Burch, Chris",
  booktitle = "Findings of the Association for Computational Linguistics: EACL 2023",
  month = may,
  year = "2023",
  address = "Dubrovnik, Croatia",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/pdf/2301.10896.pdf",
  abstract = "Entities and events have long been regarded as the crux of machine reasoning. Procedural texts have received increasing attention due to the dynamic nature of involved entities and events. Existing work has focused either on entity state tracking (e.g., the temperature of a pan) or on counterfactual event reasoning (e.g., how likely am I to burn myself by touching the pan), while these two tasks are tightly intertwined. In this work, we propose CREPE, the first benchmark on causal reasoning about event plausibility based on entity states. We experiment with strong large language models and show that most models, including GPT3, perform close to chance at .30 F1, lagging far behind the human performance of .87 F1. Inspired by the finding that structured representations such as programming languages benefits event reasoning as a prompt to code language models such as Codex, we creatively inject the causal relations between entities and events through intermediate variables and boost the performance to .67 to .72 F1. Our proposed event representation not only allows for knowledge injection, but also marks the first successful attempt of chain-of-thought reasoning with code language models.",
  selected={true},
  arxiv={2301.10896},
  bibtex_show={true},
  preview={crepe.png},
  code={https://github.com/zharry29/causal_reasoning_of_entities_and_events}
}

@article{zhang2023human,
  title={Human-in-the-Loop Schema Induction},
  author={Zhang, Tianyi and Tham, Isaac and Hou, Zhaoyi and Ren, Jiaxuan and Zhou, Liyang and Xu, Hainiu and Zhang, Li and Martin, Lara J and Dror, Rotem and Li, Sha and others},
  journal={arXiv preprint arXiv:2302.13048},
  year={2023},
  abstract = "Schema induction builds a graph representation explaining how events unfold in a scenario. Existing approaches have been based on information retrieval (IR) and information extraction(IE), often with limited human curation. We demonstrate a human-in-the-loop schema induction system powered by GPT-3. We first describe the different modules of our system, including prompting to generate schematic elements, manual edit of those elements, and conversion of those into a schema graph. By qualitatively comparing our system to previous ones, we show that our system not only transfers to new domains more easily than previous approaches, but also reduces efforts of human curation thanks to our interactive interface.",
  arxiv={2302.13048},
  bibtex_show={true},
  preview={schema-induction.png},
  website={https://www.youtube.com/watch?v=myru-fozVWI}
}

@misc{zhang2023exploring,
      title={Exploring the Curious Case of Code Prompts}, 
      author={Li Zhang and Liam Dugan and Hainiu Xu and Chris Callison-Burch},
      year={2023},
      eprint={2304.13250},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      preview={codex.png},
      bibtex_show={true},
      abstract= "Recent work has shown that prompting language models with code-like representations of natural language leads to performance improvements on structured reasoning tasks. However, such tasks comprise only a small subset of all natural language tasks. In our work, we seek to answer whether or not code-prompting is the preferred way of interacting with language models in general. We compare code and text prompts across three popular GPT models (davinci, code-davinci-002, and text-davinci-002) on a broader selection of tasks (e.g., QA, sentiment, summarization) and find that with few exceptions, code prompts do not consistently outperform text prompts. Furthermore, we show that the style of code prompt has a large effect on performance for some but not all tasks and that fine-tuning on text instructions leads to better relative performance of code prompts.",
      code={https://github.com/zharry29/codex_vs_gpt3}
}
