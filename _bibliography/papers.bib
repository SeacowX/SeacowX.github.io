---
---
@inproceedings{zhang-etal-2023-causal,
  title = "Causal Reasoning of Entities and Events in Procedural Texts",
  author = "Zhang*, Li  and
  Xu*, Hainiu  and Yang, Yue  and Zhou, Shuyan  and
  You, Weiqiu  and
  Arora, Manni  and
  Callison-Burch, Chris",
  booktitle = "Findings of the Association for Computational Linguistics: EACL 2023",
  month = may,
  year = "2023",
  address = "Dubrovnik, Croatia",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/pdf/2301.10896.pdf",
  abstract = "Entities and events have long been regarded as the crux of machine reasoning. Procedural texts have received increasing attention due to the dynamic nature of involved entities and events. Existing work has focused either on entity state tracking (e.g., the temperature of a pan) or on counterfactual event reasoning (e.g., how likely am I to burn myself by touching the pan), while these two tasks are tightly intertwined. In this work, we propose CREPE, the first benchmark on causal reasoning about event plausibility based on entity states. We experiment with strong large language models and show that most models, including GPT3, perform close to chance at .30 F1, lagging far behind the human performance of .87 F1. Inspired by the finding that structured representations such as programming languages benefits event reasoning as a prompt to code language models such as Codex, we creatively inject the causal relations between entities and events through intermediate variables and boost the performance to .67 to .72 F1. Our proposed event representation not only allows for knowledge injection, but also marks the first successful attempt of chain-of-thought reasoning with code language models.",
  selected={true},
  arxiv={2301.10896},
  bibtex_show={true},
  preview={crepe.png},
  code={https://github.com/zharry29/causal_reasoning_of_entities_and_events}
}

@article{zhang2023human,
  title={Human-in-the-Loop Schema Induction},
  author={Zhang*, Tianyi and Tham*, Isaac and Hou*, Zhaoyi and Ren, Jiaxuan and Zhou, Liyang and Xu, Hainiu and Zhang, Li and Martin, Lara J and Dror, Rotem and Li, Sha and others},
  journal={arXiv preprint arXiv:2302.13048},
  year={2023},
  abstract = "Schema induction builds a graph representation explaining how events unfold in a scenario. Existing approaches have been based on information retrieval (IR) and information extraction(IE), often with limited human curation. We demonstrate a human-in-the-loop schema induction system powered by GPT-3. We first describe the different modules of our system, including prompting to generate schematic elements, manual edit of those elements, and conversion of those into a schema graph. By qualitatively comparing our system to previous ones, we show that our system not only transfers to new domains more easily than previous approaches, but also reduces efforts of human curation thanks to our interactive interface.",
  arxiv={2302.13048},
  bibtex_show={true},
  preview={schema-induction.png},
  website={https://www.youtube.com/watch?v=myru-fozVWI}
}

@article{hainiu2023thesis,
  title={Fine-grained and Coarse-grained Causal Reasoning in Procedural Texts},
  author={Xu, Hainiu and Callison-Burch, Chris},
  journal={School of Engineering and Applied Sciences, University of Pennsylvania},
  year={2023},
  abstract = "The ability to make causal inferences is inherent to humans and substantial to our intelli- 
gence and civilization. Yet, such a crucial capability is lacking even in the state-of-the-art 
Large Language Models (LLMs). To pave the pathway toward Artificial General Intelli- 
gence, granting machines a similar capability of conducting causal inferences is an indis- 
pensable building block. Causalities come in different granularity. At a coarse-grained level, 
causal relations exist between events. At a fine-grained level, causal relations exist between 
events and participating entities. From an event-centric perspective, an intelligent agent 
shall be able to infer the causal effects that one event could bring to related entities as 
well as other events. For instance, the event of heating up a pan will cause the attribute, 
temperature, of the participating entity, pan, to rise. Being able to comprehend the causal 
effect of events at both a coarse-grained and fine-grained level will bring significant ben- 
efits to downstream tasks such as commonsense reasoning, multi-hop question answering, 
planning, and so on. My thesis research focused on constructing benchmarks and building 
learning systems that can (1) discern entity state changes by inferring their causal relation- 
ship with events; (2) estimate the likelihood of an event happening by deducing its causal 
relation with context entities; (3) mitigate reporting bias in languages by leveraging external 
modalities such as vision (video) to provide extra information on participating entities; and 
(4) constructing dynamic causal diagrams based on fine-grained entity state information in 
procedural texts.",
  bibtex_show={true},
  preview={thesis.png},
  website={https://seacowx.github.io/assets/pdf/master-thesis.pdf},
}

@misc{zhang2023exploring,
      title={Exploring the Curious Case of Code Prompts}, 
      author={Li Zhang* and Liam Dugan* and Hainiu Xu* and Chris Callison-Burch},
      year={2023},
      eprint={2304.13250},
      arxiv={2304.13250v1},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      preview={codex.jpg},
      selected={true},
      bibtex_show={true},
      abstract= "Recent work has shown that prompting language models with code-like representations of natural language leads to performance improvements on structured reasoning tasks. However, such tasks comprise only a small subset of all natural language tasks. In our work, we seek to answer whether or not code-prompting is the preferred way of interacting with language models in general. We compare code and text prompts across three popular GPT models (davinci, code-davinci-002, and text-davinci-002) on a broader selection of tasks (e.g., QA, sentiment, summarization) and find that with few exceptions, code prompts do not consistently outperform text prompts. Furthermore, we show that the style of code prompt has a large effect on performance for some but not all tasks and that fine-tuning on text instructions leads to better relative performance of code prompts.",
      code={https://github.com/zharry29/codex_vs_gpt3}
}
